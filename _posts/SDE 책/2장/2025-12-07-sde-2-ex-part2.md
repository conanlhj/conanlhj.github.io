---
layout: post
title: "[SDE] 2.3 Exercises (Part 2)"
date: 2025-12-07 14:18 +0900
description: "책 2장의 연습문제 풀이 (Part 2) 문제 2.5 ~ 2.10"
author: shiggy
categories: [공부, "확률미분방정식(SDE)"]
tag:   [sde, stochastic calculus, measure theory, probability space, random variable, lp space, stochastic process, kolmogorov extension theorem, brownian motion, gaussian process]
pin: false
math: true
mermaid: true
toc: true
comments: true
render_with_liqueid: true
---

## 시작에 앞서..

> 이 포스팅 시리즈는 Diffusion을 공부하다 SDE를 공부해야한다는 생각으로 혼자 책을 읽으며 정리한 글입니다. Bernt Øksendal 교수님의 책 "Stochastic Differential Equations: An Introduction with Applications[^1]"을 참고하여 작성하였습니다.
{:.prompt-tip}

---

## Ex. 2.5.

> **2.5**
>
> $X, Y : \Omega \to \mathbb{R}$이 서로 독립인 두 확률변수라고 하자. 또한 단순화를 위해 $X$랑 $Y$가 유계(bounded)라고 가정하자. 다음을 증명하라:
>
> $$ E[XY] = E[X]E[Y]. $$
>
> > **힌트**  
> > $\lvert X \rvert \leq M, \lvert Y \rvert \leq N$이라 하자. $X$와 $Y$를 각각 다음과 같은 단수함수 (simple functions)로 근사한다:
> >
> > $$ \varphi(\omega) = \sum_{i=1}^m a_i \chi_{F_i}(\omega), \quad \psi(\omega) = \sum_{j=1}^n b_j \chi_{G_j}(\omega), $$
> >
> > 여기서 $F_i = X^{-1}([a_i, a_{i+1}))$이고 $G_j = Y^{-1}([b_j, b_{j+1}))$이다. 그리고 구간 분할은 다음과 같이 둔다:
> >
> > $$ -M = a_0 < a_1 < \cdots < a_m = M,  \quad -N = b_0 < b_1 < \cdots < b_n = N. $$
> > 
> > 그러면
> >
> > $$ E[X] \approx E[\varphi] = \sum_i a_i P(F_i), \quad E[Y] \approx E[\psi] = \sum_j b_j P(G_j), $$
> > 
> > 그리고
> >
> > $$ E[XY] \approx E[\varphi \psi] = \sum_{i,j} a_i b_j P(F_i \cap G_j). $$
{:.example-box}

<details markdown="1">
<summary>📂 풀이</summary>

먼저 $\chi$는 우리가 [Ex. 2.1]({% post_url 2025-12-06-sde-2-ex-part1 %}) 에서 봤던 지시함수 $\mathbf{1}$과 동일한 의미이다. (처음에 뭔가 했다...)

이 문제에서 주어진 힌트를 계속 이어가보자. 문제의 마지막 부분에서 $E[XY]$를 근사하는 식이 다음과 같이 주어져 있었다:

$$ 
E[\varphi \psi] = \sum_{i,j} a_i b_j P(F_i \cap G_j).
$$

문제에서 $X$와 $Y$는 서로 독립이고, 사건 $F_i$와 $G_j$는 각각 $X$와 $Y$에 의해서만 정리되었으므로, $P(F_i \cap G_j) = P(F_i) P(G_j)$이므로, 다음과 같이 쓸 수 있다:

$$
\begin{aligned}
E[\varphi \psi] &= \sum_{i,j} a_i b_j P(F_i) P(G_j) \\
&= \left( \sum_i a_i P(F_i) \right) \left( \sum_j b_j P(G_j) \right) \\
&= E[\varphi] E[\psi].
\end{aligned}
$$

이렇게 하면, 우리는 단순 함수에 대해서는 $E[\varphi \psi] = E[\varphi] E[\psi]$임을 알 수 있다. 하지만 우리는 원래의 함수 $X$와 $Y$에 대해서 이 성질을 증명해야 한다. 이를 위해 우리는 단순 함수 $\varphi$와 $\psi$가 각각 $X$와 $Y$에 점점 더 가까워지도록 구간 분할을 세밀하게 만들고, 구간을 0으로 좁혀가는 극한 과정을 생각할 수 있다.

$$
\begin{aligned}
E[XY] &= E[\lim_{m \to \infty} \varphi \lim_{n \to \infty} \psi] \\
&= \lim_{m \to \infty} \lim_{n \to \infty} E[\varphi \psi] \\
&= \lim_{m \to \infty} \lim_{n \to \infty} E[\varphi] E[\psi] \\
&= \left( \lim_{m \to \infty} E[\varphi] \right) \left( \lim_{n \to \infty} E[\psi] \right) \\
&= E[X] E[Y].
\end{aligned}
$$

중간에 $\lim$이 기댓값 밖으로 나올 수 있던 이유는, 앞 문제(Ex. 2.1)처럼 DCT(지배 수렴 정리)가 성립하기 때문이다. 따라서, 우리는 $E[XY] = E[X] E[Y]$임을 증명할 수 있다.

(증명 끝)

</details>

---

## Ex. 2.6.

> **2.6**
>
> $(\Omega, \mathcal{F}, P)$를 확률 공간이라 하고, $A_1, A_2, \dots$를 $\mathcal{F}$에 속하는 사건들이라고 하자. 또한 다음 조건이 성립한다고 하자:
>
> $$ \sum_{k=1}^{\infty} P(A_k) < \infty. $$
>
> 이때 *Borel-cantelli lemma*를 증명하라:
>
> $$ P \left( \bigcap_{m=1}^{\infty} \bigcup_{k=m}^{\infty} A_k \right) = 0. $$
>
> 즉 "$\omega$가 무한히 많은 $A_k$에 속할 확률이 0임을 보여라."
{:.example-box}

<details markdown="1">
<summary>📂 풀이</summary>

문제에서 주어진 lemma가 무엇을 의미하는지를 생각하는 것 부터가 오래걸렸다. 문제에서 증명하라는 것을 먼저 짚고 넘어가보자.

$$
B_m = \bigcup_{k=m}^{\infty} A_k
$$

먼저 $B_m$이 의미하는 것은 $m$번째 사건 $A_m$부터 시작해서 그 이후의 모든 사건들의 합집합이다. 즉, 어떤 $\omega$가 $B_m$에 속한다는 것은, $\omega$가 $A_m, A_{m+1}, A_{m+2}, \dots$ 중 적어도 하나에는 속한다는 뜻이다.

$$
E = \bigcap_{m=1}^{\infty} B_m
$$

이 식이 의미하는 것은 $m$이 무한대로 커질 때까지 모든 $B_m$에 속하는 $\omega$들의 집합이다. 즉, 어떤 $\omega$가 이 교집합에 속한다는 것은, 임의의 $m$에 대해서도 $\omega$가 $A_m, A_{m+1}, A_{m+2}, \dots$ 중 적어도 하나에는 속한다는 뜻이다. 다시 말해, 어떤 $\omega$가 이 교집합에 속한다면, 그 $\omega$는 무한히 많은 $A_k$에 속하게 된다.

예를 들어서, 어떤 $\omega$가 $A_{1000}$ 속한다고 해보자. 그러면 이 $\omega$는 $B_{1000}$까지는 속하게 되겠지만, 그 이후의 $B_k$에는 속하지 못하게 된다.

이 정리가 결국 말하고자 하는 것은, "만약 $P(A_k)$들의 합이 유한하다면,(확률의 합이 유한하다면) 언젠가 그 사건은 일어나지 않는다."를 말하고 있다.

이제 증명해보자.

$B_1 \supseteq B_2 \supseteq B_3 \supseteq \cdots$이다. ($B_m$은 감소하는 사건열이다.)

$$
P(E) = P \left(  \bigcap_{m=1}^{\infty} B_m \right) = \lim_{m \to \infty} P(B_m)
$$

이제 $P(B_m)$에 관한 부등식을 세워보자. 각 사건 $A_k$는 서로소인지 모르므로, 합집합의 확률은 각 사건의 확률의 합보다 작거나 같다는 것을 이용한다.

$$
P(B_m) = P \left( \bigcup_{k=m}^{\infty} A_k \right) \leq \sum_{k=m}^{\infty} P(A_k)
$$

문제의 가정에서 $\sum_{k=1}^{\infty} P(A_k) < \infty$이므로 $P(A_k)$는 수렴하는 급수이다. 수렴하는 급수에서 $m \to \infty$일 때, $\sum_{k=m}^{\infty} P(A_k) \to 0$이므로, 다음과 같이 쓸 수 있다:

$$
0 \leq P(E) = \lim_{m \to \infty} P(B_m) \leq \lim_{m \to \infty} \sum_{k=m}^{\infty} P(A_k) = 0.
$$

샌드위치 정리에 의해, $P(E) = 0$임을 알 수 있다.

(증명 끝)

</details>

---

## Ex. 2.7.

> **2.7**
>
> 1. 서로소(disjoint)인 집합 $G_1, G_2, \dots, G_n \subset \Omega$이 다음 조건을 만족한다고 하자:
>
>     $$ \Omega = \bigcup_{i=1}^n G_i. $$
>
>     이때,
>     - $\varnothing$, 그리고
>     - $G_1, \dots, G_n$ 중 일부(또는 전부)
>     
>     를 합쳐 만든 모든 가능한 합집합들로 이루어진 집합족$\mathcal{G}$가 $\Omega$ 위의 $\sigma$-algebra임을 보여라.
>
> 2. 어떤 $\sigma$-algebra $\mathcal{F}$가 유한(finite)하다면, 그 $\sigma$-algebra는 반드시 (a)에서 설명한 형태임을 보여라.
>
> 3. $\mathcal{F}$가 $\Omega$ 위의 유한 $\sigma$-algebra라고 하고, $X : \Omega \to \mathbb{R}$가 $\mathcal{F}$-measurable하다고 하자. 이때, $X$는 *오직 유한 개의 값*만 취한다는 것을 보여라.  
> 더 구체적으로는 서로소인 집합들 $F_1, F_2, \dots, F_m \in \mathcal{F}$과 실수 $c_1, \dots, c_m$이 존재하여,
> 
>     $$ X(\omega) = \sum_{i=1}^m c_i \chi_{F_i}(\omega) $$
>
>     가 됨을 증명하라. 즉, 유한 $\sigma$-algebra 위에서 측정 가능한 함수는 항상 simple function이다.
{:.example-box}

<details markdown="1">
<summary>📂 풀이</summary>

<details markdown="1">
<summary><strong>2.7.a)</strong></summary>

$\sigma$-algebra의 3가지 조건을 차례대로 증명한다.

**1. $\varnothing$의 포함**  
$\varnothing \in \mathcal{G}$이므로, $\sigma$-algebra의 첫 조건은 만족한다.

**2. 여집합에 대한 닫힘**  
두 번째로, $\mathcal{G}$에 속하는 임의의 집합 $A \in \mathcal{G}$에 대해서, $A$의 여집합 $A^C$도 $\mathcal{G}$에 속함을 보여야 한다. $A$는 $G_1, G_2, \dots, G_n$ 중 일부(또는 전부)를 합쳐 만든 집합이므로, $I = \\{1, 2, \dots, n\\}$과 어떤 $J \subseteq I$에 대해 다음과 같이 표현 가능하다:

$$
A = \bigcup_{j \in J} G_j.
$$

여집합을 취하면 드 모르간의 법칙에 의해:

$$
A^C = \left( \bigcup_{j \in J} G_j \right)^C = \bigcap_{j \in J} G_j^C.
$$

그런데, $G_j$들은 서로소이므로, $G_j^C$는 다음과 같이 쓸 수 있다:

$$
G_j^C = \Omega \setminus G_j = \bigcup_{i \neq j} G_i.
$$

즉, $A^C$는 다음과 같이 표현된다:

$$
A^C = \bigcap_{j \in J} \left( \bigcup_{i \neq j} G_i \right) = \bigcup_{i \notin J} G_i.
$$

따라서, $A^C$ 역시 $G_1, G_2, \dots, G_n$ 중 일부(또는 전부)를 합쳐 만든 집합이므로, $A^C \in \mathcal{G}$이다.

직관적으로 생각해보면, 전체 $\Omega$가 퍼즐 조각($G_i$)들로 가득 채워져 있기 때문에 일부의 조각을 빼면 나머지 조각들이 여집합을 이루게 된다. 수식으로 이 직관을 표현하는게 오히려 어려웠다..

**3. 가산 합집합에 대한 닫힘**  
마지막으로, $\mathcal{G}$에 속하는 임의의 집합열 $A_1, A_2, \dots \in \mathcal{G}$에 대해서, 그 합집합 $\bigcup_{k=1}^{\infty} A_k$도 $\mathcal{G}$에 속함을 보여야 한다. 각 $A_k$는 $G_1, G_2, \dots, G_n$ 중 일부(또는 전부)를 합쳐 만든 집합이므로, $J_k \subseteq I$과 $A_k$에 대해 다음과 같이 표현 가능하다:

$$
A_k = \bigcup_{j \in J_k} G_j,
$$

그러면 합집합은 다음과 같이 쓸 수 있다:

$$
\bigcup_{k=1}^{\infty} A_k = \bigcup_{k=1}^{\infty} \left( \bigcup_{j \in J_k} G_j \right) = \bigcup_{j \in \bigcup_{k=1}^{\infty} J_k} G_j.
$$

여기서 $\bigcup_{k=1}^{\infty} J_k$는 $I$의 부분집합이므로, 합집합 역시 $G_1, G_2, \dots, G_n$ 중 일부(또는 전부)를 합쳐 만든 집합이 된다. 따라서, $\bigcup_{k=1}^{\infty} A_k \in \mathcal{G}$이다.

위 1, 2, 3의 조건을 모두 만족하므로, $\mathcal{G}$는 $\Omega$ 위의 $\sigma$-algebra이다.

(증명 끝)


</details>

<details markdown="1">
<summary><strong>2.7.b)</strong></summary>

이 문제는 결국, 유한한 $\sigma$-algebra는 반드시 어떤 유한 개의 서로소 집합들((a)에서의 $G_i$)로 분할된 형태여야 한다는 것을 증명하는 것이다. 이를 증명하기 위해 우리는 $\omega \in \Omega$에 대해 $\omega$를 포함하는 가장 작은 $\mathcal{F}$의 원소를 생각해보자. 즉, 다음과 같이 정의한다:

$$
A_\omega = \bigcap \{ A \in \mathcal{F} : \omega \in A \}.
$$

이렇게 정의한 $A_\omega$는 흔히 atom이라고 불리는 개념이다. 이제 우리는 다음과 같은 사실들을 증명해야 한다:
1. 각 $A_\omega$는 $\mathcal{F}$에 속한다.
2. 서로 다른 두 $A_\omega$와 $A_{\omega'}$는 서로소이거나 같다.
3. 모든 $A_\omega$의 합은 $\Omega$를 이룬다.

**1. 각 $A_\omega$는 $\mathcal{F}$에 속한다.**  
문제에서 $\mathcal{F}$가 유한하다고 했으므로, $\\{ A \in \mathcal{F} : \omega \in A \\}$는 유한한 집합이다. 따라서, 유한 개의 집합의 교집합은 다시 $\mathcal{F}$에 속하므로(가산 합집합에 대해서 닫혀있다는 것과 여집합에 대해서 닫혀있다는 것, 그리고 드 모르간의 법칙을 통해 증명할 수 있다), $A_\omega \in \mathcal{F}$이다. 

**2. 서로 다른 두 $A_\omega$와 $A_{\omega'}$는 서로소이거나 같다.**  
임의의 두 원소 $\omega, \omega' \in \Omega$에 대해, 만약 $A_\omega \cap A_{\omega'} \neq \varnothing$이라면, $z \in A_\omega \cap A_{\omega'}$인 어떤 $z$가 존재한다는 뜻이다. $z$를 포함한 가장 작은 집합 $A_z$를 생각해보자. 그러면, $A_z \subseteq A_\omega$이다. 하지만, $A_\omega$는 더 이상 작은 조각으로 쪼개질 수 없고, $A_z$도 비어있지 않고 $A_w$의 부분집합이므로, $A_\omega \subseteq A_z$이다. 따라서, $A_\omega = A_z$이다. 마찬가지로, $A_{\omega'} = A_z$이므로, $A_\omega = A_{\omega'}$이다.

반대로, $A_\omega \cap A_{\omega'} = \varnothing$이라면, 두 집합은 서로소이다.(서로소의 정의 그 자체이다.)

**3. 모든 $A_\omega$의 합은 $\Omega$를 이룬다.**  
모든 $\omega \in \Omega$에 대해 모든 $\omega$는 적어도 하나의 $A_\omega$에 속한다. 그런데 $\omega$ 전부의 합집합이 $\Omega$이므로, $\omega$를 포함한 집합들의 합집합도 $\Omega$일 수 밖에 없다.

따라서, 우리는 $\mathcal{F}$가 유한하다면, $\mathcal{F}$는 반드시 (a)에서 설명한 형태임을 증명할 수 있다.

(증명 끝)

</details>

<details markdown="1">
<summary><strong>2.7.c)</strong></summary>

(b)를 통해 우리는 $\mathcal{F}$가 유한 $\sigma$-algebra라면, $\mathcal{F}$는 $G_1, G_2, \dots, G_n$이라는 서로소 집합들로 분할된 형태임을 알 수 있다. $G_k$의 원소 $\omega_0 \in G_k$에 대해 다음을 정의하자:

$$
c_k = X(\omega_0).
$$

이제, $X$가 $\mathcal{F}$-measurable하다는 것은, 임의의 Borel 집합 $B \subseteq \mathbb{R}$에 대해 $X^{-1}(B) \in \mathcal{F}$임을 의미한다. 특히, $B = \\{ c_k \\}$인 경우를 생각해보자. 그러면,

$$
E = X^{-1}(\{ c_k \}) = \{ \omega \in \Omega : X(\omega) = c_k \} \in \mathcal{F}.
$$

$\omega_0 \in G_k$, $\omega_0 \in E$이고, $G_k$는 더 이상 쪼개질 수 없는 집합(atom)이므로, $G_k \subseteq E$일 수 밖에 없다.

하지만, $\forall \omega \in E$에서 $X(\omega) = c_k$를 가지므로, $G_k \subseteq E$인 $G_k$역시 $\forall \omega \in G_k$에 대해서 $X(\omega) = c_k$를 만족한다.

따라서, 우리는 다음과 같이 쓸 수 있다:

$$
X(\omega) = \sum_{i=1}^n c_i \chi_{G_i}(\omega).
$$

결론적으로 $X$는 오직 유한 개의 값만 취하며, simple function임을 증명할 수 있다.

(증명 끝)


</details>

</details>

---

## Ex. 2.8.

> **2.8**
>
> $B_t$를 $\mathbb{R}$ 위의 Brownian motion이라 하고, $B_0 = 0$이라 하자. 또한 기대값 $E$는 확률측도 $P$에 대한 기대값 $E^0$을 의미한다고 하자.
>
> 1. 식 (2.2.3)을 사용하여 다음을 보여라:
>
>     $$ E\!\left[ e^{iu B_t} \right] = \exp\!\left( -\frac{1}{2}u^2 t \right), \qquad \text{for all } u \in \mathbb{R}. $$
>
> 2. 양변에 대해 지수함수(exp) 의 멱급수(power series) 전개를 적용하고, 동일한 차수의 $u$ 항을 비교하여 다음을 유도하라:
>
>     $$ E\!\left[ B_t^4 \right] = 3t^2,$$
>
>     더 나아가 다음을 보이라:
>
>     $$ E\!\left[ B_t^{2k} \right] = \frac{(2k)!}{2^k \cdot k!} \, t^k, \qquad k \in \mathbb{N}. $$
>
> 3. 만약 (b)의 전개 과정이 충분히 엄밀하지 않다고 느껴진다면, 다음과 같은 방법으로 진행할 수도 있다. 식 (2.2.2)가 다음을 함의함을 보이라:
>
>     $$ E[f(B_t)] = \frac{1}{\sqrt{2\pi t}} \int_{\mathbb{R}} f(x) \, e^{-\tfrac{x^2}{2t}} \, dx, $$
>
>     > 단, 우변의 적분이 수렴하는 모든 함수 $f$에 대해 위 식이 성립해야 한다.
>    
>     그런 다음 $f(x) = x^{2k}$ 로 두고 부분적분(integration by parts)과 $k$에 대한 귀납법(induction)을 사용하여 (b)의 결론을 다시 유도하라.
>
> 4. (b)의 결과와 차원 $n$에 대한 귀납법을 사용하여, 식 (2.2.14)가 성립함을 증명하라.
{:.example-box}

여기서 식 (2.2.3)과 (2.2.2), 그리고 (2.2.14)는 각각 다음과 같다:

$$
E^x\!\left[ \exp\!\left( i \sum_{j=1}^{nk} u_j Z_j \right) \right]
=
\exp\!\left(
- \frac{1}{2}\sum_{j,m} u_j c_{jm} u_m
+ i \sum_j u_j M_j
\right)
\tag{2.2.3}
$$

$$
P^x (B_{t_1} \in F_1, \cdots, B_{t_k} \in F_k) = \int_{F_1 \times \cdots \times F_k} p(t_1, x, x_1) \cdot p(t_2 - t_1, x_1, x_2) \cdots p(t_k - t_{k-1}, x_{k-1}, x_k) d x_1 \cdots d x_k \tag{2.2.2}
$$

$$
E^x [ \lvert B_t - B_s \rvert^4] = n(n+2) \lvert t - s \rvert^2 \tag{2.2.14}
$$

<details markdown="1">
<summary>📂 풀이</summary>

<details markdown="1">
<summary><strong>2.8.a)</strong></summary>

식 (2.2.3)은 얼핏 보기에는 너무 무서워 보이지만, 우리는 $n=1$(1차원 브라운 운동)이고, 시점이 하나($k=1$)인 경우를 생각하고 있다.

식 (2.2.3)에서 필요한 값들을 하나씩 찾아보자.
- 변수 $u_1$은 그냥 $u$
- 공분산 $C$에 대한 $c_{jm}$는 그냥 분산이다. $c_{11} = Var(B_t) = t$
- 평균 $M$은 우리가 $B_0 = 0$에서 시작하는 브라운 운동이라고 했으므로, $M = E[B_t] = 0$

따라서, 식 (2.2.3)은 다음과 같이 단순화된다:

$$
\begin{aligned}
E\!\left[ e^{iu B_t} \right] &= \exp\!\left( - \frac{1}{2} u \cdot t \cdot u + i \cdot u \cdot 0 \right) \\
&= \exp\left( -\frac{1}{2} u^2 t \right).
\end{aligned}
$$

(증명 끝)

</details>

<details markdown="1">
<summary><strong>2.8.b)</strong></summary>

양변에 taylor series 전개를 적용해보자.

먼저 좌변을 전개하면:

$$
\begin{aligned}
E[e^{i u B_t}] &= E\left[ \sum_{n=0}^{\infty} \frac{(i u B_t)^n}{n!} \right] \\
&= \sum_{n=0}^{\infty} \frac{(i u)^n}{n!} E[B_t^n].
\end{aligned}
$$

우변을 전개하면:

$$
\begin{aligned}
e^{-\frac{1}{2} u^2 t} &= \sum_{m=0}^{\infty} \frac{1}{m!} \left( -\frac{1}{2} u^2 t \right)^m \\
&= \sum_{m=0}^{\infty} \frac{(-1)^m}{2^m m!} u^{2m} t^m.
\end{aligned}
$$

**먼저 $E[B_t^4]$을 구해보자**  
양변에서 $u^4$ 항의 계수를 비교하면, 좌변에는 $n=4$, 우변에는 $m=2$인 항이 대응된다. 따라서:

$$
\begin{aligned}
\frac{(i)^4}{4!} E[B_t^4] &= \frac{(-1)^2}{2^2 \cdot 2!} t^2. \\
E[B_t^4] &= \frac{4!}{2^2 \cdot 2!} t^2 \\
&= 3 t^2.
\end{aligned}
$$

**다음으로 일반적인 $E[B_t^{2k}]$을 구해보자**  
양변에서 $u^{2k}$ 항의 계수를 비교하면, 좌변에는 $n=2k$, 우변에는 $m=k$인 항이 대응된다. 따라서:

$$
\begin{aligned}
\frac{(i)^{2k}}{(2k)!} E[B_t^{2k}] &= \frac{(-1)^k}{2^k \cdot k!} t^k. \\
E[B_t^{2k}] &= \frac{(2k)!}{2^k \cdot k!} t^k.
\end{aligned}
$$

(증명 끝)

</details>

<details markdown="1">
<summary><strong>2.8.c)</strong></summary>

식 (2.2.2)를 사용해서 이번에는 직접 적분하여 계산해보자. (참고로 나는 (b)의 전개 과정이 충분히 엄밀하다고 느껴졌다... ㅠㅠ)

(2.2.2)의 식이 무섭고 어렵게 느껴지지만, 우리는 시점 $t$에서의 브라운 운동 $B_t$에 대해서만 생각하고 있으므로, $k=1$이고, $t_1 = t$이다. 따라서, 식 (2.2.2)는 다음과 같이 단순화된다:

$$
P^0 (B_t \in F) = \int_{F} p(t, 0, x) \, d x.
$$

식이 갑자기 앙증맞고 귀여워졌다. $p(t, 0, x)$는 브라운 운동의 확률밀도함수이므로, 다음과 같이 쓸 수 있다:

$$
p(t, 0, x) = \frac{1}{\sqrt{2 \pi t}} e^{-\frac{x^2}{2t}} = \mathcal{N}(0, t).
$$

우리는 $E[f(B_t)]$를 구하고자 하므로, LOTUS에 의해 다음과 같이 쓸 수 있다:

$$
E[f(B_t)] = \int_{\mathbb{R}} f(x) \, p(t, 0, x) \, d x = \frac{1}{\sqrt{2 \pi t}} \int_{\mathbb{R}} f(x) \, e^{-\frac{x^2}{2t}} \, d x.
$$

다음으로 $f(x) = x^{2k}$로 두고, 부분적분과 귀납법을 사용하여 $E[B_t^{2k}]$를 구해보자.

$$
E[B_t^{2k}] = \frac{1}{\sqrt{2 \pi t}} \int_{\mathbb{R}} x^{2k} e^{-\frac{x^2}{2t}} \, d x.
$$

부분적분을 사용하기 위해 다음과 같이 치환한다:
- $u = x^{2k - 1}, \quad du = (2k - 1) x^{2k - 2} d x$
- $d v = x e^{-\frac{x^2}{2t}} d x, \quad v = -t e^{-\frac{x^2}{2t}}$

이제 부분적분을 적용하면:

$$
\begin{aligned}
\int_{\mathbb{R}} x^{2k} e^{-\frac{x^2}{2t}} \, d x &= \int_{\mathbb{R}} u \, d v \\
&= \left. u v \right|_{-\infty}^{\infty} - \int_{\mathbb{R}} v \, d u \\
&= \left. - x^{2k - 1} t e^{-\frac{x^2}{2t}} \right|_{-\infty}^{\infty} + t (2k - 1) \int_{\mathbb{R}} x^{2k - 2} e^{-\frac{x^2}{2t}} \, d x \\
&= t (2k - 1) \int_{\mathbb{R}} x^{2k - 2} e^{-\frac{x^2}{2t}} \, d x.
\end{aligned}
$$

이제 양 변에 $\frac{1}{\sqrt{2 \pi t}}$를 곱하면:

$$
\begin{aligned}
\frac{1}{\sqrt{2 \pi t}} \int_{\mathbb{R}} x^{2k} e^{-\frac{x^2}{2t}} \, d x &= t (2k - 1) \cdot \frac{1}{\sqrt{2 \pi t}} \int_{\mathbb{R}} x^{2k - 2} e^{-\frac{x^2}{2t}} \, d x \\
E[B_t^{2k}] &= t (2k - 1) E[B_t^{2k - 2}].
\end{aligned}
$$

우리는 점화식을 얻었다. $E[B_t^0] = 1$임을 알고 있으므로, 귀납법에 의해 다음과 같이 쓸 수 있다:

$$
\begin{aligned}
E[B_t^{2k}] &= t (2k - 1) E[B_t^{2k - 2}] \\
&= t (2k - 1) \cdot t (2k - 3) E[B_t^{2k - 4}] \\
&= t^k (2k - 1)(2k - 3) \cdots 3 \cdot 1 \cdot E[B_t^0] \\
&= t^k \frac{(2k)!}{2^k \cdot k!}.
\end{aligned}
$$

이 식은 (b)에서 구한 식과 동일하다.

(증명 끝)

</details>

<details markdown="1">
<summary><strong>2.8.d)</strong></summary>

(b)에서 구한 결과에 따르면,

$$
E[B^2_t] = t, \quad E[B^4_t] = 3 t^2.
$$

수식을 편하게 쓰기 위해 $\Delta t : = t - s$라고 하자. 그리고 Brownian motion의 특성 상 $B_t - B_s$의 분포는 $\mathcal{N}(0, \Delta t)$이다.

$n=1$인 경우,

$$
E[|B_t - B_s|^4] = 3 (\Delta t)^2. = (1)(1 + 2) (\Delta t)^2.
$$

이는 식 (2.2.14)에서 $n=1$인 경우와 일치한다. 이제, n차원 Brownian motion을

$$
B_t = (B_t^{(1)}, B_t^{(2)}, \dots, B_t^{(n)}),
$$

라고 쓰자. 여기서 각 $B_t^{(i)}$는 독립적인 1차원 Brownian motion이다. 증분 벡터를

$$
X := B_t - B_s = (X^{(1)}, X^{(2)}, \dots, X^{(n)}), \quad X^{(i)} := B_t^{(i)} - B_s^{(i)},
$$

라고 두면, 각 $X^{(i)}$는 독립적인 $\mathcal{N}(0, \Delta t)$ 분포를 따른다. 따라서 위의 결과를 그대로 사용할 수 있다.

$$
E[(X^{(i)})^2] = \Delta t, \quad E[(X^{(i)})^4] = 3 (\Delta t)^2.
$$

우리가 구하고자 하는 것은 다음과 같다:

$$
E \left[ \lvert B_t - B_s \rvert^4 \right] = E \left[ \lvert X \rvert^4 \right].
$$

귀납법 사용을 위해 어떤 $n=k$에 대해 다음이 성립한다고 가정하자:

$$
E[|X_n|^4] = k (k + 2) (\Delta t)^2.
$$

독립인 1차원 Brownian 증분 $Y \sim \mathcal{N}(0, \Delta t)$를 하나 더 붙여서 $X_{n+1} = (X_n, Y)$라고 정의하자. 그러면,

$$
\begin{aligned}
E[|X_{n+1}|^4] &= E[(|X_n|^2 + Y^2)^2] \\
&= E[| X_n |^4 + 2 | X_n |^2 Y^2 + Y^4] \\
&= E[| X_n |^4] + 2 E[| X_n |^2 Y^2] + E[Y^4] \\
&= E[| X_n |^4] + 2 E[| X_n |^2] \cdot E[Y^2] + E[Y^4] \\
&= k(k+2)(\Delta t)^2 + 2 \cdot (k \Delta t) \cdot (\Delta t) + 3 (\Delta t)^2 \\
&= (k + 1)(k + 3) (\Delta t)^2 \\
&= (k + 1)((k + 1) + 2) (\Delta t)^2.
\end{aligned}
$$

이므로, $n = k + 1$에 대해서도 성립한다. 따라서, 귀납법에 의해 식 (2.2.14)가 성립함을 증명할 수 있다.

(증명 끝)

</details>

</details>

---

## Ex. 2.9.

> **2.9**
>
> 유한 차원 분포들만으로는 어떤 확률과정의 연속성 정보를 완전히 설명할 수 없다는 것을 보여주기 위해, 다음 예제를 살펴보자.
> 
> <br>
> 
> $(\Omega, \mathcal{F}, P) = ([0, \infty), \mathcal{B}, \mu)$ 라고 하자. 여기서 $\mathcal{B}$는 $[0, \infty)$ 위의 Borel $\sigma$-algebra이고, $\mu$는 $[0, \infty)$ 위에서 점 질량이 없는(no mass on single points) 확률측도라고 하자.
>
> <br>
>
> 다음과 같은 과정을 정의한다.
>
> $$ X_t(\omega) = \begin{cases} 1, & \text{if } t = \omega, \\ 0, & \text{if } t \neq \omega. \end{cases} $$
>
> 그리고
>
> $$ Y_t(\omega) = 0, \qquad \text{for all } (t, \omega) \in [0, \infty) \times [0, \infty). $$
>
> <br>
>
> 다음을 증명하라:
> 1. 과정 $\\{X_t\\}$와 $\\{Y_t\\}$는 동일한 분포(same distributions)를 가진다.
> 2. $X_t$는 $Y_t$의 한 version이다.
> 3. 그런데도 $t \mapsto Y_t(\omega)$는 모든 $\omega$에 대해 연속인 반면, $t \mapsto X_t(\omega)$는 모든 $\omega$에 대해 불연속이다.
{:.example-box}

<details markdown="1">
<summary>📂 풀이</summary>

<details markdown="1">
<summary><strong>2.9.a)</strong></summary>

임의의 시점들 $t_1, t_2, \dots, t_k \in [0, \infty)$를 고정하자.

$Y_t(\omega)$는 모든 $\omega$에 대해 항상 0이므로, 벡터 $(Y_{t_1}, Y_{t_2}, \dots, Y_{t_k})$는 항상 영벡터 $(0, 0, \dots, 0)$가 된다. (확률 1)

벡터 $(X_{t_1}, X_{t_2}, \dots, X_{t_k})$를 생각해보자. 이 벡터가 영벡터가 아닌 경우는 적어도 하나의 $i$에 대해 $X_{t_i}(\omega) = 1$이어야 한다. 정의상 이는 $\omega = t_i$일 때 발생한다.

$$
\begin{aligned}
P((X_{t_1}, X_{t_2}, \dots, X_{t_k}) \neq \mathbf{0}) &= P\left( \bigcup_{i=1}^k \{ \omega : X_{t_i}(\omega) = 1 \} \right) \\
&= P\left( \bigcup_{i=1}^k \{ \omega : \omega = t_i \} \right) \\
&\leq \sum_{i=1}^k P(\{ \omega : \omega = t_i \}) \\
&= \sum_{i=1}^k \mu(\{ t_i \}).
\end{aligned}
$$

그런데 $\mu$는 점 질량이 없는 확률측도이므로, $\mu(\{ t_i \}) = 0$이다. 따라서,

$$
P((X_{t_1}, X_{t_2}, \dots, X_{t_k}) \neq \mathbf{0}) = 0.
$$

즉, $X$의 유한 차원 분포 역시 확률 1로 영벡터가 되므로, $X$와 $Y$는 동일한 분포를 가진다.

(증명 끝)

</details>

<details markdown="1">
<summary><strong>2.9.b)</strong></summary>

$X_t$와 $Y_t$의 version이 되기 위해서는 모든 $t \in [0, \infty)$에 대해 $P(X_t = Y_t) = 1$이어야 한다. 임의의 시점 $t$에 대해 두 확률변수가 다를 사건 $X_t \neq 0$인 경우, 즉 $\omega = t$인 경우뿐이다.

$$
\begin{aligned}
P(X_t \neq Y_t) &= P(X_t \neq 0) \\
&= P(\{ \omega : \omega = t \}) \\
&= \mu(\{ t \}) \\
&= 0.
\end{aligned}
$$

따라서 $P(X_t = Y_t) = 1$이므로, $X_t$는 $Y_t$의 한 version이다.

(증명 끝)

</details>

<details markdown="1">
<summary><strong>2.9.c)</strong></summary>

이제 $\omega$를 하나 고정하고, $t$에 대한 함수(경로)로서 살펴보자.

- 함수 $t \mapsto Y_t(\omega)$는 모든 $t$에 대해 0인 상수함수이다. 따라서 연속이다.
- 함수 $t \mapsto X_t(\omega)$는 다음과 같다.

    $$
    X_t(\omega) = \begin{cases} 1, & \text{if } t = \omega, \\ 0, & \text{if } t \neq \omega. \end{cases}
    $$

    이 함수는 $t = \omega$에서 불연속이다. 왜냐하면, $\lim_{t \to \omega} X_t(\omega) = 0$이지만, $X_{\omega}(\omega) = 1$이기 때문이다. 따라서, $X_t(\omega)$는 모든 $\omega$에 대해 불연속이다.

(증명 끝)

</details>

</details>

---

## Ex. 2.10.

> **2.10**
>
> 확률과정 $X_t$가 stationary 하다는 것은 모든 $h > 0$에 대해 과정 $\\{X_t \\}$와 $\\{X_{t+h} \\}$가 동일한 분포(same distributions)를 가진다는 것을 의미한다. Brownian motion $B_t$가 stationary increments를 가진다는 것을 보여라. 즉, 과정 $\\{B_{t+h} - B_t \\}_{h \geq 0}$는 모든 $t$에 대해 동일한 분포를 가진다는 것을 증명하라.
{:.example-box}

<details markdown="1">
<summary>📂 풀이</summary>

새로운 확률 과정을 생각해보자:

$$
Y_h := B_{t+h} - B_t, \quad h \geq 0.
$$

임의의 두 시점 $0 \leq h_i < h_j$를 잡자. $Y_{h_j} - Y_{h_i}$의 분포가 $t$와 무관하다면, 우리는 $Y_h$가 모든 $t$에 대해 동일한 분포를 가진다는 것을 증명할 수 있다.

$$
Y_{h_j} - Y_{h_i} = (B_{t+h_j} - B_t) - (B_{t+h_i} - B_t) = B_{t+h_j} - B_{t+h_i}.
$$

Brownian motion의 정의에 의해, 증분 $B_{t+h_j} - B_{t+h_i}$는 평균이 0이고 분산이 시간 차이 $(t+h_j) - (t+h_i) = h_j - h_i$인 정규분포 $\mathcal{N}(0, h_j - h_i)$를 따른다.

$$
Y_{h_j} - Y_{h_i} \sim \mathcal{N}(0, h_j - h_i).
$$

이 분포는 $t$에 의존하지 않고, 오직 시간 간격 $h_j - h_i$에만 의존한다.

확률 과정 $Y_h$는 $Y_0 - B_t - B_t = 0$으로 시작하며, 모든 유한 차원 분포는 $Y_0$와 위에서 구한 증분들의 합으로 표현될 수 있다.

구성 요소인 모든 증분의 분포가 $t$와 무관하므로, 이들의 결합으로 이루어진 과정 $\\{ Y_h \\} _ {h \geq 0}$의 모든 유한 차원 분포 또한 $t$와 무관하다. 따라서 과정 $\\{B_{t+h} - B_t\\}_{h \geq 0}$는 모든 $t$에 대해 동일한 분포를 가진다.

(증명 끝)

</details>

---
## Reference

[^1]: Bernt Øksendal, *Stochastic Differential Equations*, Springer, 2003. DOI: [10.1007/978-3-642-14394-6](https://doi.org/10.1007/978-3-642-14394-6).
