---
layout: post
title: "[SDE] 2.1 확률론의 기초 언어 (Part 1): 공간, 변수, 그리고 기댓값과 독립성"
date: 2025-12-04 16:45 +0900
description: "Bernt Øksendal 교수의 Stochastic Differential Equations: An Introduction withb Applications 책 내용 정리"
author: shiggy
categories:
- 공부
- 확률미분방정식(SDE)
tag:
- [stochastic calculus, stochastic differential equations, stochastic process]
pin: false
math: true
mermaid: true
toc: true
comments: true
render_with_liqueid: true
---

## 시작에 앞서..

> 이 포스팅 시리즈는 Diffusion을 공부하다 SDE를 공부해야한다는 생각으로 혼자 책을 읽으며 정리한 글입니다. Bernt Øksendal 교수님의 책 "Stochastic Differential Equations: An Introduction with Applications[^1]"을 참고하여 작성하였습니다.
{:.prompt-tip}

---

1장에서는 우리가 다루고자 하는 문제들(필터링, 옵션 프라이싱 등)을 소개했다. 이제 이 문제들을 수학적으로 엄밀하게 기술하기 위한 도구들을 정의할 차례다. 건물을 짓기 위해 벽돌과 시멘트의 성질을 먼저 알아야 하는 것과 같다.

이번 포스팅에서는 책 2.1장의 전반부를 다룬다. 여기서 우리는 다음 질문들에 대한 수학적 모델을 정의한다.

1.  **무작위(Random) 양**이란 무엇인가?
2.  **독립성(Independence)**이란 무엇인가?
3.  이들을 다루는 **공간(Space)**은 어떻게 생겼는가?

---

## 1. 확률 공간 (Probability Space)

확률을 논하기 위해서는 우리가 '노는 물', 즉 공간을 정의해야 한다. 단순히 직관에 의존하면 모순(예: Banach-Tarski 역설)이 발생할 수 있기 때문에, 수학자들은 집합론을 기반으로 매우 엄밀한 규칙을 세웠다.

### 1.1 $\sigma$-algebra (사건들의 모임)

가장 먼저 전체 집합 $\Omega$와, 우리가 '확률을 잴 수 있는' 부분집합들의 모임인 $\mathcal{F}$를 정의한다.

> **Definition 2.1.1 ($\sigma$-algebra)**
> 
> 주어진 집합 $\Omega$에 대해, 다음 성질을 만족하는 부분집합들의 모임(family) $\mathcal{F}$를 $\sigma$-algebra라고 한다.
>
> 1.  $\varnothing \in \mathcal{F}$ (공집합을 포함한다.)
> 2.  $F \in \mathcal{F} \Rightarrow F^{C} \in \mathcal{F}$ (여집합에 대해 닫혀있다.)
> 3.  $A_1, A_2, \dots \in \mathcal{F} \Rightarrow \bigcup_{i=1}^{\infty} A_i \in \mathcal{F}$ (가산 합집합에 대해 닫혀있다.)
{:.definition-box}

이때 쌍 $(\Omega, \mathcal{F})$를 **가측 공간(Measurable space)**이라고 부른다.

예를 들어, 동전을 한 번 던지는 상황을 생각해보자.
* $\Omega = \\{H, T \\}$ (앞면, 뒷면)
* 가장 작은 $\sigma$-algebra: $\mathcal{F}_{trivial} = \\{ \varnothing, \Omega \\}$ (아무 정보도 없는 상태)
* 가장 큰 $\sigma$-algebra: $\mathcal{F}_{all} = \\{ \varnothing, \{H\}, \{T\}, \Omega \\}$ (모든 경우의 수를 다 따질 수 있음)

만약 $\mathcal{F} = \\{ \varnothing, \{H\}, \Omega \\}$라고 한다면 이건 $\sigma$-algebra가 아니다. 왜냐하면 $\{H\}$의 여집합인 $\\{T\\}$가 없기 때문이다. 즉, "앞면이 나왔다"는 알 수 있는데 "뒷면이 나왔다"는 모른다는 것은 논리적으로 말이 안 된다.

### 1.2 확률 측도 (Probability Measure)

공간이 정의되었으니, 이제 각 사건에 '확률'이라는 숫자를 부여하는 함수 $P$를 정의하자.

> **Definition (Probability Measure)**
> 
> 가측 공간 $(\Omega, \mathcal{F})$ 위의 확률 측도 $P$는 다음 조건을 만족하는 함수 $P : \mathcal{F} \rightarrow [0, 1]$이다.
>
> 1.  $P(\varnothing) = 0, \quad P(\Omega) = 1$
> 2.  가산 가법성 (Countable Additivity): 서로소(disjoint)인 집합열 $A_1, A_2, \dots \in \mathcal{F}$ ($A_i \cap A_j = \varnothing, i \neq j$)에 대해,
> 
> $$ P \left( \bigcup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} P (A_i) $$
{:.definition-box}

이 세 가지 요소의 삼중항 $(\Omega, \mathcal{F}, P)$를 **확률 공간(Probability space)**이라고 부른다.

### 1.3 완비성 (Completeness)

확률론을 엄밀하게 다룰 때, 우리의 직관과 수학적 정의 사이에 미묘한 구멍이 생길 수 있다. **완비성(Completeness)**은 이 구멍을 메우기 위한 개념이다.

어떤 구멍을 말하는지 간단한 예를 들어보자. 우리가 $[0, 1]$ 구간에서 바늘을 하나 던져서 숫자를 뽑는다고 치자.
* 특정한 점 하나, 예를 들어 $0.5$가 정확히 나올 확률은 0이다. ($P(\{0.5\}) = 0$)
* 그렇다면 $\{0.5\}$라는 집합의 **부분집합**은 어떨까? (물론 원소가 하나뿐이라 부분집합은 공집합 아니면 자기 자신이겠지만, 원소가 많은 집합이라고 상상해보자.)
* 상식적으로 **"확률 0인 사건 안에 포함된 더 작은 사건"**이라면, 당연히 그 확률도 0이어야 한다.

하지만 수학적으로는 문제가 생길 수 있다. 우리가 정의한 사건들의 모임($\mathcal{F}$)에 그 **'작은 사건'이 목록에 없을 수도 있기 때문**이다. 목록에 없으면 확률($P$)을 정의조차 할 수 없다. 이것이 바로 **"Incomplete(불완전)"**한 상황이다.

이 문제를 해결하기 위해 먼저 **"목록($\mathcal{F}$)에 없는 집합의 크기를 밖에서 재보자"**는 아이디어를 도입한다. 이를 **Outer measure(외측도, $P^*$)**라고 한다.

$$
P^*(G) := \inf \{ P(F) \mid F \in \mathcal{F}, \ G \subset F \}
$$

이 수식이 의미하는 바를 하나씩 뜯어보자. 우리가 크기를 재고 싶은, 하지만 목록($\mathcal{F}$)에는 없는 집합을 $G$라고 하자.

1.  **$F \in \mathcal{F}, \ G \subset F$**: 목록에 있는 '정식 사건'들 중에서, $G$를 덮을 수 있는(포함하는) 녀석들($F$)을 찾는다.
2.  **$P(F)$**: 그 덮개($F$)들의 확률을 잰다.
3.  **$\inf$ (Infimum)**: 그 확률들 중 가장 작은 값(하한)을 찾는다. 즉, $G$를 감싸는 가장 타이트한 포장지를 찾는 것이다.

만약 $G$를 감싸는 가장 작은 포장지의 확률마저 0 이라면 ($P^*(G)=0$), $G$는 실질적으로 확률이 0이어야 마땅하다.

> **Definition (Complete Probability Space)**
> 
> 만약 $P^*(G) = 0$을 만족하는 모든 집합 $G$가 $\mathcal{F}$에 정식으로 포함되어 있다면($G \in \mathcal{F}$), 이 확률 공간을 완비(Complete)되었다고 한다.
{:.definition-box}

쉽게 말해 **"확률이 0인 사건의 부분집합들도 모두 '사건'으로 인정해주고, 확률 0을 부여하자"**는 약속이다.

대부분의 표준적인 확률 공간(예: Borel $\sigma$-algebra)은 태생적으로 완비가 아니다. 하지만 우리는 언제나 "확률이 0인 집합의 부분집합들"을 $\mathcal{F}$에 강제로 추가하여 공간을 완비하게 만들 수 있다(Completion).

따라서 이 책과 앞으로의 포스트에서는 **"우리의 확률 공간은 항상 Complete하다"**고 가정한다. 덕분에 우리는 "almost surely" 같은 개념을 쓸 때, 수학적 모순을 걱정하지 않고 편하게 이야기할 수 있다.

---

## 2. 확률 변수 (Random Variables)

이제 확률 공간 위에 **확률 변수**를 정의한다. 대학생 시절 확률과통계 수업에서는 $X$를 단순히 '변수'처럼 취급했지만, 해석학적 관점에서는 $X$는 $\Omega$에서 실수 공간 $\mathbb{R}^n$으로 가는 **함수**다.

### 2.1 정의와 가측성 (Measurability)

이제 확률 공간 위에 **확률 변수(Random Variable)**라는 배우를 등장시켜 보자. 이름은 '변수'지만, 수학적 실체는 $\Omega$의 원소를 실수($\mathbb{R}$)로 바꿔주는 **함수**다.

하지만 아무 함수나 확률 변수가 될 수 있는 건 아니다. 반드시 **가측성(Measurability)**이라는 자격 요건을 갖춰야 한다.

> **Definition (Random Variable)**
>
> 확률 공간 $(\Omega, \mathcal{F}, P)$가 주어졌을 때, 함수 $X : \Omega \rightarrow \mathbb{R}^n$가 $\mathcal{F}$-measurable하다면, 이를 확률 변수라고 한다. 여기서 $\mathcal{F}$-measurable이란, 모든 Borel set(구간 등) $U \subset \mathbb{R}^n$에 대해 다음을 만족하는 것이다.
>
> $$X^{-1}(U) := \{ \omega \in \Omega : X(\omega) \in U \} \in \mathcal{F}$$
{:.definition-box}

이 복잡한 수식의 의미는 간단하다. **"결과값에 대한 질문을 던졌을 때, 확률로 대답할 수 있는가?"**이다.

1.  우리는 결과값 공간($\mathbb{R}$)에서 질문을 던진다. (예: "$X$가 0보다 클 확률은?")
2.  이 질문은 원래의 표본 공간($\Omega$)의 사건으로 번역된다. (역상: $\{\omega \mid X(\omega) > 0\}$)
3.  **핵심:** 번역된 이 사건이 우리 **'사건의 목록($\mathcal{F}$)'**에 들어 있어야 한다.

목록($\mathcal{F}$)에 들어있지 않다면, 확률($P$)이 정의되어 있지 않으므로 우리는 확률을 계산할 수 없다. 즉, **확률을 잴 수 없는 함수는 확률 변수 자격 박탈**이다.

예시를 들어보자. 동전 던지기를 하는데, 눈을 감고 있어서 동전이 던져졌다는 사실만 알고 앞/뒤는 모르는 상황을 가정해 보자.

* $\Omega = \\{H, T\\}$ (앞, 뒤)
* $\mathcal{F} = \\{\varnothing, \Omega\\}$ (정보가 없음: 아무것도 안 일어남, 혹은 무언가 일어남)

이때, **"앞면이면 100원, 뒷면이면 -100원"**을 주는 내기 함수 $X$를 정의해보자.
$$X(H) = 100, \quad X(T) = -100$$

이제 **"내가 100원을 받을 확률($P(X=100)$)은?"**이라고 물어보자.
1.  **질문:** $U = \\{100\\}$
2.  **역상:** $X^{-1}(\\{100\\}) = \\{H\\}$ (앞면이 나와야 함)
3.  **확인:** 그런데 $\{H\}$는 우리의 목록 $\mathcal{F}$에 **없다**.

따라서 우리는 확률을 말할 수 없다. 이 경우 함수 $X$는 이 공간에서 **확률 변수가 될 수 없다.** (정보 $\mathcal{F}$가 너무 빈약해서 $X$를 받아들일 수 없는 상태다.)

### 2.2 생성된 $\sigma$-algebra ($\mathcal{H}_X$)

확률 변수 $X$는 단순히 값을 뱉어내는 함수가 아니다. $X$는 우리에게 **정보(Information)**를 제공하는 원천이다. $X$의 관측값들을 통해 역으로 "아, 원래 세상($\Omega$)에서 무슨 일이 일어났구나!"를 추론할 수 있는 사건들의 모임을 **생성된 $\sigma$-algebra**라고 한다.

$$
\mathcal{H}_X = \{ X^{-1}(B) \mid B \in \mathcal{B} \}
$$

(여기서 $\mathcal{B}$는 $\mathbb{R}^n$ 위의 Borel $\sigma$-algebra이다.)

이 $\mathcal{H}_X$는 $X$를 가측(measurable)으로 만드는 **가장 작은 $\sigma$-algebra**이다.

$\mathcal{H}_X$는 **"$X$만 쳐다보고 있을 때, 구분할 수 있는 사건들의 목록"**이다.
$X$가 알려주지 않는 정보는 $\mathcal{H}_X$에 포함되지 않는다. 즉, $\mathcal{H}_X$가 작을수록 정보가 적고(뭉뚱그려져 있고), 클수록 정보가 많다(세밀하다).

1부터 6까지 있는 주사위를 던지는 상황을 생각해보자.
* $\Omega = \\{1, 2, 3, 4, 5, 6\\}$

이때, 주사위의 눈을 그대로 알려주는 게 아니라, **"짝수면 1, 홀수면 0"**만 알려주는 불친절한 확률 변수 $X$가 있다고 하자.

$$
X(\omega) = \begin{cases} 1 & (\omega \in \{2, 4, 6\}) \\ 0 & (\omega \in \{1, 3, 5\}) \end{cases}
$$

이제 우리는 $X$의 값만 알 수 있다. $X$가 생성하는 정보 $\mathcal{H}_X$는 무엇일까?

1.  만약 $X=1$을 관측했다면? $\rightarrow$ "아, $\{2, 4, 6\}$ 중 하나가 일어났구나!" (구분 가능)
2.  만약 $X=0$을 관측했다면? $\rightarrow$ "아, $\{1, 3, 5\}$ 중 하나가 일어났구나!" (구분 가능)
3.  하지만 "$2$가 나왔니?"라고 묻는다면? $\rightarrow$ $X$만 봐서는 $2$인지 $4$인지 $6$인지 알 길이 없다. 즉, 사건 $\{2\}$는 $\mathcal{H}_X$에 속하지 않는다.

결국 이 $X$가 생성한 $\sigma$-algebra는 다음과 같이 아주 작은 집합족이 된다.
$$
\mathcal{H}_X = \{ \varnothing, \Omega, \{1, 3, 5\}, \{2, 4, 6\} \}
$$

### 2.3 Doob-Dynkin Lemma

이 레마는 조건부 기댓값 등을 다룰 때 매우 중요하게 사용된다. "어떤 확률 변수가 다른 확률 변수의 정보 안에 포함된다"는 것이 수식으로 어떤 의미인지 보여준다.

> **Lemma 2.1.2 (Doob-Dynkin)**
>
> 두 함수 $X, Y : \Omega \rightarrow \mathbb{R}^n$가 주어졌을 때, $Y$가 $\mathcal{H}_X$-measurable하다는 것은, 어떤 Borel measurable 함수 $g : \mathbb{R}^n \rightarrow \mathbb{R}^n$가 존재하여
>
> $$Y = g(X)$$
>
> 로 표현된다는 것과 동치(iff)이다.
{:.definition-box}

즉, $Y$가 $X$의 정보량($\mathcal{H}_X$) 안에 종속되어 있다면, $Y$는 사실상 $X$의 함수 꼴일 수밖에 없다는 강력한 정리다.

앞선 예시를 다시 가져와 보자. 주사위를 던졌는데 $X$는 우리에게 **홀/짝 정보**만 알려준다. ($\Omega = \\{1, \dots, 6\\}$)

$$
X(\omega) = \begin{cases} 1 & (\omega \in \{2, 4, 6\}) \\ 0 & (\omega \in \{1, 3, 5\}) \end{cases}
$$

**상황 A: $X$만 보고 계산 가능한 $Y$ (Measurable)**  
내기 함수 $Y$가 "짝수면 500원을 받고, 홀수면 0원"이라고 하자.

* $Y$의 값은 $\\{0, 500\\}$ 중 하나다.
* 우리는 $X$의 값(1 또는 0)만 알면 $Y$가 얼마인지 **100% 확신**할 수 있다.
* 즉, $Y$는 $X$의 함수로 표현된다. ($g(x) = 500x$)
* 따라서 $Y$는 $\mathcal{H}_X$-measurable 하다.

**상황 B: $X$만 봐서는 모르는 $Z$ (Not Measurable)**  
다른 내기 함수 $Z$가 "주사위 눈이 **6**이면 1000원을 받는다"라고 하자.
* $X=1$(짝수)이라는 정보를 받았다. 그렇다면 내 돈 $Z$는 얼마일까?
* 주사위가 2나 4였다면 $Z=0$원이고, 6이었다면 $Z=1000$원이다.
* $X$는 2, 4, 6을 구분해 주지 못하므로, $X$값만 가지고는 $Z$를 하나의 값으로 정할(계산할) 수 없다.
* 즉, $Z = g(X)$ 꼴로 나타낼 수 없으며, $Z$는 $\mathcal{H}_X$-measurable 하지 않다.

따라서 "$Y$가 $X$에 대해 가측이다"라는 말은, **"$X$의 값만 알면 $Y$의 값도 자동으로 계산된다($Y=g(X)$)"**는 말과 똑같다.

---

## 3. 기댓값 (Expectation)과 분포 (Distribution)

확률 변수 $X$를 정의했다면, 이제 그 $X$가 대략 어디쯤에 위치하는지(기댓값), 얼마나 퍼져있는지(분산)를 계산하고 싶을 것이다. 이를 위해서는 **분포(Distribution)**와 **적분(Integration)**의 개념을 연결해야 한다.

### 3.1 분포 (Distribution): 확률의 "이사(Moving)"

확률 변수 $X$는 추상적인 공간 $\Omega$에 흩뿌려져 있던 확률 $P$를, 우리가 잘 아는 실수 공간 $\mathbb{R}^n$으로 '퍼 나르는' 역할을 한다. 이를 **유도된 측도(Induced Measure)** 또는 **분포(Distribution)**라고 한다.

$$\mu_X(B) = P \left( X^{-1}(B) \right)$$

* **$P$:** $\Omega$라는 미지의 세계(근원적인 사건들)에서 작동하는 확률.
* **$\mu_X$:** $\mathbb{R}^n$이라는 익숙한 숫자 세계(결과값)에서 작동하는 확률.

이 수식이 의미하는 바를 구체적인 예시로 뜯어보자.

주머니 안에 공이 들어있다. 우리는 이 공들의 물리적 특성($\Omega$)을 숫자인 상금($\mathbb{R}$)으로 바꾸고 싶다.

1.  **공간 설정 ($\Omega$와 $P$)**:
    * $\Omega = \\{ \text{Gold, Silver, Stone} \\}$
    * 주머니 안의 확률: $P(\\{\text{Gold}\\}) = 0.1$, $P(\\{\text{Silver}\\}) = 0.3$, $P(\\{\text{Stone}\\}) = 0.6$

2.  **확률 변수 ($X$)**: 공을 상금으로 바꿔주는 규칙
    * $X(\text{Gold}) = 100$원
    * $X(\text{Silver}) = 50$원
    * $X(\text{Stone}) = 0$원

3.  **분포 ($\mu_X$)의 계산**:
    이제 우리는 "주머니"를 잊고, **"상금의 확률"**만 알고 싶다. 예를 들어, **"50원을 받을 확률($\mu_X(\\{50\\}))$은 얼마인가?"**

    이 질문에 답하기 위해 수식을 따라가 보자.
    
    $$
    \mu_X(\{50\}) = P( X^{-1}(\{50\}) )
    $$
    
    * **Step 1 ($X^{-1}$):** 50원을 주는 근원 사건이 뭐였지? $\rightarrow$ "Silver"
    * **Step 2 ($P$):** 그럼 Silver가 나올 확률이 얼마였지? $\rightarrow$ $0.3$
    * **결과:** 따라서 $\mu_X(\{50\}) = 0.3$

결국 **분포 $\mu_X$**란, $\Omega$ 공간에 있던 $0.1, 0.3, 0.6$이라는 확률 덩어리들을, $X$라는 사다리를 타고 실수 축 위의 점 $100, 50, 0$ 위치로 **그대로 옮겨 놓은 것**이다.

이제 우리는 복잡한 주머니 속을 들여다보지 않고도, 실수 축 위에서 "평균 상금(기댓값)" 등을 편하게 계산할 수 있게 되었다.

### 3.2 기댓값의 정의와 LOTUS
기댓값 $E[X]$의 본래 정의는 추상적인 공간 $\Omega$ 위에서의 적분이다. (단, 적분 가능 조건 $\int_\Omega | X | dP < \infty$ 만족 시)

$$
E[X] := \int_\Omega X(\omega) dP(\omega)
$$

하지만 이 정의대로 계산하려면 우리는 모든 근원 사건 $\omega$를 일일이 알아야 한다. 이건 너무 힘들다. 우리는 $\Omega$ 대신 우리가 익숙한 $\mathbb{R}^n$에서 적분하고 싶다. 이때 등장하는 구세주가 바로 **LOTUS**다.

> **Theorem (LOTUS: Law of the Unconscious Statistician)**
>
> $f : \mathbb{R}^n \rightarrow \mathbb{R}$가 Borel measurable이고 적분 가능하면, 다음 등식이 성립한다.
>
> $$E[f(X)] := \int_\Omega f \left( X(\omega) \right) d P(\omega) = \int_{\mathbb{R}^n} f(x) d \mu_X (x)$$
{:.theorem-box}

이 정리의 이름이 **"무의식적인 통계학자의 법칙"**인 이유는, 대부분의 통계학자(그리고 우리들)가 자신이 적분 변수를 $\Omega$에서 $\mathbb{R}$로 **치환적분**하고 있다는 사실조차 인지하지 못한 채(Unconscious), 너무나 당연하게 오른쪽 식을 써왔기 때문이다.

앞선 **색깔 공 예시**를 다시 가져와 보자.
* $\Omega = \\{ \text{Gold, Silver, Stone} \\}$
* $P$: Gold(0.1), Silver(0.3), Stone(0.6)
* $X$: Gold $\to$ 100, Silver $\to$ 50, Stone $\to$ 0

이제 우리가 상금 그 자체가 아니라, 상금을 받았을 때 느끼는 **'만족도'의 기댓값**을 구하고 싶다고 하자. 만족도는 상금의 제곱에 비례한다고 가정한다. ($f(x) = x^2$)

**방법 1: 정의대로 계산 ($\Omega$ 위에서의 적분)**  
이 방식은 **"주머니 속에 손을 넣어서 공을 하나씩 꺼내보는"** 방식이다. 공($\omega$)을 확인하고, 그 공의 상금을 제곱해서 확률을 곱한다.

$$
\begin{aligned}
E[X^2] &= \int_\Omega X(\omega)^2 dP(\omega) \\
&= 100^2 \cdot P(\text{Gold}) + 50^2 \cdot P(\text{Silver}) + 0^2 \cdot P(\text{Stone}) \\
&= 10000 \cdot 0.1 + 2500 \cdot 0.3 + 0 \cdot 0.6
\end{aligned}
$$

**방법 2: LOTUS를 이용한 계산 ($\mathbb{R}$ 위에서의 적분)**  
이 방식은 공은 쳐다보지 않고 **"점수판(분포)만 보는"** 방식이다. 상금($x$)이 나올 확률($\mu_X$)을 이미 계산해 뒀다면, 바로 계산할 수 있다.

$$
\begin{aligned}
E[X^2] &= \int_{\mathbb{R}} x^2 d\mu_X(x) \\
&= 100^2 \cdot \mu_X(\{100\}) + 50^2 \cdot \mu_X(\{50\}) + 0^2 \cdot \mu_X(\{0\}) \\
&= 10000 \cdot 0.1 + 2500 \cdot 0.3 + 0 \cdot 0.6
\end{aligned}
$$

두 계산의 결과는 같다. 하지만 **방법 2(LOTUS)** 덕분에 우리는 "Gold 공이 무거운지 가벼운지" 같은 $\Omega$의 구체적인 사정은 몰라도, **"100원 나올 확률이 10%다"**라는 **분포(pdf/pmf)**만 알면 기댓값을 편하게 계산할 수 있는 것이다.

---

## 4. $L^p$ 공간과 독립성 (The $L^p$-spaces & Independence)

확률 변수 하나하나는 '함수'라고 했다. 이제 우리는 이 함수들을 다 모아놓은 **'함수 공간(Function Space)'**을 생각해보자.

수학자들이 공간을 정의할 때 가장 신경 쓰는 것은 **"크기(Norm)"**와 **"거리(Metric)"**를 잴 수 있느냐는 것이다. 그래야 "이 확률 변수가 저 확률 변수로 수렴한다"는 식의 극한 논의를 할 수 있기 때문이다.

### 4.1 $L^p$-spaces

확률 변수 $X$가 가질 수 있는 값의 '크기'를 정의하기 위해 $L^p$-norm을 도입한다. $p \in [1, \infty)$인 상수에 대해 다음과 같이 정의한다.

$$
\Vert X \Vert _ p = \Vert X \Vert _{L^p(P)}
= \left( \int_{\Omega} |X(\omega)|^p dP(\omega) \right)^{1/p}
$$

**특수한 경우 ($p=\infty$):**  
가장 큰 값을 의미하지만, 확률론에서는 확률이 0인 사건(무시해도 되는 사건)을 제외하고 생각해야 한다. 이를 **본질적 상한(Essential supremum)**이라고 한다. (직관적으로는, 확률 0인 예외 케이스를 다 지우고 났을 때의 최댓값이다.)

$$
\Vert X \Vert _ \infty = \inf \{ C \ge 0 : P(|X| > C) = 0 \}
$$

이제 이 Norm이 유한한 확률 변수들의 모임을 $L^p$ 공간이라고 한다.

$$
L^p(P) = \{ X : \Omega \to \mathbb{R}^n \mid \Vert X \Vert _p < \infty \}
$$

이 공간은 수학적으로 매우 좋은 성질을 가진다.
* **Banach Space:** $L^p$ 공간은 **완비 노름 선형 공간(Complete Normed Linear Space)**이다. 즉, 코시 수열이 수렴하는 '구멍 없는' 공간이다. (연습문제 2.19 참고)

SDE 이론에서 가장 사랑받는 공간은 $p=2$일 때인 **$L^2(P)$ 공간**이다. 이 공간은 단순히 Banach Space인 것을 넘어, **Hilbert Space(힐베르트 공간)**가 된다. 힐베르트 공간이란 **내적(Inner Product)**이 정의되는 완비 공간을 말한다.

$$
(X, Y)_{L^2(P)} := E[X \cdot Y], \qquad X, Y \in L^2(P)
$$

이 **내적**의 존재가 왜 중요할까? 내적이 있으면 **'각도'**를 잴 수 있고, **'직교(Orthogonal)'** 개념을 도입할 수 있기 때문이다.
* 우리는 나중에 다룰 Itô Integral을 $L^2$ 공간에서의 '직교 투영'이나 '피타고라스 정리' 같은 기하학적 직관을 이용해 다루게 된다.

### 4.2 독립성 (Independence)

마지막으로, 확률론의 핵심 개념인 '독립'을 엄밀하게 정의해보자. 직관적으로는 "서로 영향을 주지 않음"이지만, 수학적으로는 **"교집합의 확률이 곱하기로 쪼개짐"**으로 정의된다.

> **Definition 2.1.3 (Independence)**
>
> 1.  사건의 독립: 두 사건 $A, B \in \mathcal{F}$가 독립이라는 것은 다음이 성립할 때이다.
>
> $$P( A \cap B) = P(A) \cdot P(B)$$
>
> 2.  $\sigma$-algebra의 독립: $\sigma$-algebra들의 집합족 $$\{ \mathcal{H}_i ; i \in I \}$$가 독립이라는 것은, 서로 다른 인덱스 $i_1, \dots, i_k$를 뽑아서 각 $$\mathcal{H}_{i_k}$$에서 사건 $H_{i_k}$를 가져왔을 때, 다음이 성립하는 것이다.
> 
>     $$P(H_{i_1} \cap \cdots \cap H_{i_k}) = P(H_{i_1}) \cdots P(H_{i_k})$$
> 
> 3.  확률 변수의 독립: 확률 변수들의 집합 $$\{ X_i \}_{i \in I}$$가 독립이라는 것은, 그들이 생성하는 $\sigma$-algebra들의 집합 $$\{ \mathcal{H}_{X_i} \}$$가 독립이라는 뜻이다.
{:.definition-box}
만약 두 확률 변수 $X, Y$가 독립이고 각각 적분 가능하다면($E[|X|], E[|Y|] < \infty$), 기댓값은 곱셈에 대해 분리된다. (연습문제 2.5 참고)

$$
E[XY] = E[X]E[Y]
$$

이를 앞서 배운 **$L^2$ 내적**의 관점에서 해석해보면 흥미롭다.

$$
(X, Y)_{L^2} = E[X]E[Y]
$$

만약 $X$나 $Y$ 둘 중 하나의 평균이 0이라면 ($E[X]=0$ or $E[Y]=0$),

$$
(X, Y)_{L^2} = 0
$$

이 된다. 즉, **"독립이면서 평균이 0인 확률 변수들은 $L^2$ 공간에서 서로 수직(Orthogonal)이다."**

이 기하학적 직관(독립 $\approx$ 직교)은 SDE의 잡음 항(Noise term)을 다룰 때 핵심적인 역할을 하게 된다.

---

### 🚀 Part 1 마무리 및 예고

지금까지 우리는 확률론의 **정적인(Static)** 기초를 다졌다.
하지만 우리가 진짜 관심 있는 것은 **'변화'**다. 주가는 시간이 흐르며 변하고, 입자는 시간이 흐르며 움직인다.

다음 포스팅(**Part 2**)에서는 시간 $t$를 도입하여 **확률 과정(Stochastic Process)**을 정의하고, "우리가 상상하는 확률 과정이 수학적으로 진짜 존재하는가?"를 보장해 주는 **Kolmogorov's Extension Theorem**에 대해 다룰 것이다.

---
## Reference

[^1]: Bernt Øksendal, *Stochastic Differential Equations*, Springer, 2003. DOI: [10.1007/978-3-642-14394-6](https://doi.org/10.1007/978-3-642-14394-6).
