---
layout: post
title: "[Stochastic Differential Equations, SDE] Ch.2 Some Mathematical Preliminaries (1)"
date: 2025-03-25 18:25 +0900
description: "Bernt Øksendal 교수의 Stochastic Differential Equations: An Introduction withb Applications 책 내용 정리"
author: shiggy
categories:
- 공부
- 확륢미분방정식(SDE)
tag:
- [probability spaces, stochastic differential equations, stochastic process, random variables, brownian motion]
pin: false
math: true
mermaid: true
toc: true
comments: true
render_with_liqueid: true
---

## 시작에 앞서..

> 이 포스팅 시리즈는 Diffusion을 공부하다 SDE를 공부해야한다는 생각으로 혼자 책을 읽으며 정리한 글입니다. Bernt Øksendal 교수님의 책 "Stochastic Differential Equations: An Introduction with Applications[^1]"을 참고하여 작성하였습니다.
{:.prompt-tip}

## 2. Some Mathematical Preliminaries

[이전 포스트]({% post_url 2025-03-25-sde-1 %})에서는 우리가 어떤 문제들을 풀어야 할지 정의했다. 이제 이 문제들을 풀기 위해 필요한 **수학적으로 타당한 정의**와, 각 문제에 대한 **수학적 모델**을 세워야 한다. 아래는 우리의 목표를 위해 필요한 **수학적 해석이 필요한 개념들**이다.

1. A random quantity (확률적인 양)
2. Independence (독립성)
3. Parametrized (discrete or continuous) families of random quantities (매개변수화된 확률 변수들의 집합)
4. 필터링 문제(Problem 3., 이전 챕터 참고)에서 "최적의" 추정이란 무엇을 의미하는가?
5. 필터링 문제(Problem 3.)에서 어떤 추정이 “어떤 관측에 기반한” 것이란 무엇을 의미하는가?
6. “noise” 항의 수학적 해석은 무엇인가?
7. 확률 미분 방정식의 수학적 의미는 무엇인가?

이번 장에서는 (1)~(3)에 대해서 다룬다. 다음 장에서는 (6)에 대해서 논의하고, 이는 Itô 확률 적분과 (7)의 개념으로 이어진다. 그리고 6 장에서 (4)와 (5)에 대해서 다룬다.

## 2.1 Probability Spaces, Random Variables, and Stochastic Processes

확률적인 양을 수학적으로 표현하는 기본 모델은 **random variable(확률 변수)** 이다. 이를 정의하기에 앞서, 일반적인 **probability theory(확률 이론)** 에 대해 복습해보자.

### 확률 공간

> **Definition 2.1.1**  
> 집합 $ \Omega $ 가 주어졌을 때, $ \Omega $ 위의 *$ \sigma-algebra $(시그마 대수)* $ \mathcal{F} $는 $ \Omega $의 부분집합들의 집합족이며 다음 조건들을 만족한다:
>
> 1. $ \emptyset \in \mathcal{F} $
> 2. $ F \in \mathcal{F} \Rightarrow F^C \in \mathcal{F} $, 여기서 $ F^C = \Omega \setminus F $ 는 $ F $의 여집합이다.
> 3. $ A_1, A_2, \ldots \in \mathcal{F} \Rightarrow A := \bigcup_{i=1}^{\infty} A_i \in \mathcal{F} $
{: .definition-box }

위 1, 2, 3번을 하나씩 이해해보자.

> - 먼저, 조건 (1)은 공집합이 반드시 $ \mathcal{F} $에 속해야 한다는 것을 의미한다. 확률 이론에서는 사건이 **절대 일어나지 않음**도 하나의 사건으로 다루기 때문이다.
>
> - 조건 (2)는 $ \mathcal{F} $가 여집합에 대해 닫혀있어야 한다는 것을 의미한다. 어떤 사건이 일어날 가능성을 고려할 수 있다면, 그 사건이 "일어나지 않을" 가능성도 고려할 수 있어야 한다.
>
> - 조건 (3)은 가산 합집합에 대해 닫혀있어야 한다는 것을 의미한다. $ \mathcal{F} $는 무한이 많은 사건들을 합쳐도 그 결과가 여전히 $ \mathcal{F} $에 속해야 한다. 이 성질은 가산(additive) 성질이라고 하고, 확률을 정의하고 합산하는데 필수적이다.


여기서 쌍 $ (\Omega, \mathcal{F}) $를 **측도 공간(measurable space)**이라고 한다.  
이 측도 공간 위에 정의된 **확률 측도(probability measure)** $ P $는 다음을 만족하는 함수이다:

$$
P: \mathcal{F} \to [0, 1]
$$

1. $ P(\emptyset) = 0 $, $ P(\Omega) = 1 $
2. $ A_1, A_2, \dots \in \mathcal{F} $ 이고, 서로소 (disjoint) 집합들일 때  
   ($ A_i \cap A_j = \emptyset $ for $ i \ne j $) 다음이 성립한다:

$$
P\left( \bigcup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} P(A_i)
$$

이 성질을 **가산 가법성(countable additivity)**이라고 한다.

간단히 요약하면, 전체 표본공간 $ \Omega $가 있고, 그 표본공간의 부분집합 중에서 **확률을 정의할 수 있는 사건**들의 집합 $ \mathcal{F} $가 있고, 그 사건들에 대한 **확률 측도** $ P $가 있어야 한다는 내용이다. 여기서 $ P $는 결국 사건 $ A $에 대해 $ P(A) $를 할당하는 함수이다. 그러다 보니 1번 조건은 당연히 만족하게 되고, 2번 조건의 경우 모든 사건이 서로 겹치지 않으므로, 사건이 합은 사건이 일어날 확률의 합과 같다는 것을 의미한다.

$(\Omega, \mathcal{F}, P)$는 **확률 공간(probability space)**이라고 불린다.
이 확률 공간이 **완비(complete)**[^2]하다고 불리려면, $\mathcal{F}$가 P-outer measure $0$을 가지는 $\Omega$의 모든 부분집합 $G$를 포함해야 한다. 즉 다음을 만족해야 한다:

$$
P^*(G) := \inf \lbrace P(F) \mid F \in \mathcal{F},\, G \subset F \rbrace = 0
$$

모든 확률 공간은 외측 측도 $0$을 갖는 집합들을 $\mathcal{F}$에 추가하고, $P$를 이에 맞게 확장함으로써 **완비화**할 수 있다.  
이제부터는 모든 확률 공간이 완비되어 있다고 가정한다.

$\Omega$의 부분집합 $F$ 중 $\mathcal{F}$에 속하는 것들을 **$\mathcal{F}$-측정 가능 집합(measurable sets)**이라고 한다. 확률론의 맥락에서는 이들을 **사건(events)**이라고 부르며, 다음과 같이 해석한다:

$$
P(F) = \text{“사건 $F$가 일어날 확률”}
$$

특히 $P(F) = 1$인 경우, 우리는 **“사건 $F$가 확률 1로 일어난다”**, 또는 **“거의 확실하게(almost surely, a.s.) 일어난다”**고 표현한다.

또한, $\Omega$의 부분집합들로 이루어진 어떤 집합족 $\mathcal{U}$가 주어졌을 때, $\mathcal{U}$를 포함하는 **가장 작은 시그마 대수** $\mathcal{H}_\mathcal{U}$는 다음과 같이 정의된다:

$$
\mathcal{H}_\mathcal{U} := \bigcap \lbrace \mathcal{H} \mid \mathcal{H} \text{ 는 } \Omega \text{ 위의 시그마 대수이고 } \mathcal{U} \subset \mathcal{H} \rbrace
$$

이 $\mathcal{H}_\mathcal{U}$는 $\mathcal{U}$에 의해 생성된 시그마 대수라고 부른다. (책의 Exercise 2.3. 에서 다룬다.)

### Borel 시그마 대수와 확률 변수

확률론에서 가장 자주 등장하는 시그마 대수 중 하나가 **Borel 시그마 대수**이다.
예를 들어, 어떤 위상 공간 $\Omega$ (예: $\Omega = \mathbb{R}^n$) 위에서 **모든 열린 부분집합들**을 모은 집합족 $\mathcal{U}$를 생각해 보자.
이때 $\mathcal{U}$를 포함하는 **가장 작은 시그마 대수**를 $\mathcal{H}_\mathcal{U}$라고 하고, 이를 **Borel 시그마 대수**라고 부른다:

$$
\mathcal{B} := \mathcal{H}_\mathcal{U}
$$

여기서 $\mathcal{B}$의 원소들, 즉 Borel 시그마 대수에 속하는 집합들을 **Borel 집합**이라고 한다.
이 Borel 시그마 대수는 다음과 같은 집합들을 포함한다:

- 모든 **열린 집합**
- 모든 **닫힌 집합**
- 닫힌 집합들의 **가산 합집합**  
- 열린 집합들의 **가산 교집합**  
- 위 과정을 계속 반복해서 얻어지는 복잡한 집합들

즉, $\mathbb{R}^n$ 같은 공간 위에서 우리가 "일반적으로 상상할 수 있는 거의 모든 집합"들이 $\mathcal{B}$ 안에 포함되어 있다고 할 수 있다.

이제 확률 공간 $(\Omega, \mathcal{F}, P)$가 주어졌다고 가정해보자.
이때 함수 $Y : \Omega \to \mathbb{R}^n$가 **측정 가능(measurable)**하다는 것은 다음 조건을 만족하는 것을 뜻하게 된다:

$$
Y^{-1}(U) := \lbrace \omega \in \Omega \mid Y(\omega) \in U \rbrace \in \mathcal{F}
$$

여기서 $U$는 **$\mathbb{R}^n$에서의 열린 집합**이다.

이 조건의 의미는 다음과 같다:

> 우리가 $\mathbb{R}^n$의 어떤 열린 집합 $U$를 보고,  
> 함수 $Y$가 그 안으로 들어가는 $\omega$들을 모은 집합 $Y^{-1}(U)$를 만들었을 때,  
> 그것이 **확률 공간의 시그마 대수 $\mathcal{F}$ 안에 있어야 한다.**

이 말은 곧, **$Y$에 대해서 확률을 정의할 수 있는 사건을 만들 수 있다**는 뜻이다.
(왜냐하면 $P$는 $\mathcal{F}$에 속한 집합들에 대해서만 확률을 정의할 수 있기 때문)

> 이와 같은 함수 $Y$를 **$\mathcal{F}$-측정 가능 함수** 또는 **확률 변수(random variable)**라고 부른다.

한편, 함수 $X : \Omega \to \mathbb{R}^n$가 주어졌을 때,  
이 함수로부터 생성되는 **가장 작은 시그마 대수 $\mathcal{H}_X$**를 다음과 같이 정의할 수 있다.

$$
X^{-1}(U) \in \mathcal{H}_X \quad \text{for all open } U \subset \mathbb{R}^n
$$

즉, $X$가 $\mathbb{R}^n$의 열린 집합 안에 들어가는 입력값들의 집합이 모두 포함되도록 하는, **가장 작은 시그마 대수**다.
이 시그마 대수는 $X$에 대해 "어떤 사건들이 의미가 있는가?"를 결정해주는 역할을 한다.

> 다시 말해, $\mathcal{H}_X$는 "$X$를 관찰해서 정의할 수 있는 모든 사건들의 모음"이라고 볼 수 있다.

앞서 정의한 $X$로부터 생성된 시그마 대수 $\mathcal{H}_X$는 다음과 같이 간단하게 표현될 수 있다:

$$
\mathcal{H}_X = \lbrace X^{-1}(B) \mid B \in \mathcal{B} \rbrace
$$

여기서 $\mathcal{B}$는 $\mathbb{R}^n$ 위의 **Borel 시그마 대수**이다. $X$가 어떤 Borel 집합 $B$ 안에 들어갈 확률을 생각할 때, 그 사건은 $\Omega$에서의 역상 $X^{-1}(B)$로 표현되며, 이는 곧 $\mathcal{H}_X$ 안에 포함되어야 한다.

따라서 $X$는 **$\mathcal{H}_X$-측정 가능**(measurable)하다다. 즉, $X$의 결과값이 어떤 Borel 집합 안에 들어가는지를 $\Omega$ 상에서 의미 있게 해석할 수 있다는 것이다.

이와 동시에 $\mathcal{H}_X$는 이러한 성질을 만족하는 **가장 작은 시그마 대수**가 된다. 이 말은 곧, $X$로부터 관측 가능한 정보를 가장 최소한의 방식으로 포함하는 정보 구조라는 뜻이다.

이 개념은 이론적으로 매우 유용한데, 특히 아래의 결과와 밀접하게 관련된다.

> 다음에 소개할 결과는 **Doob-Dynkin 보조정리(Doob-Dynkin Lemma)**로 불리는 결과의 특수한 경우이다.  
> 이 정리는 확률 변수 $X$에 대해 어떤 다른 함수가 $X$로 생성된 시그마 대수에 대해 측정 가능할 때, 그 함수가 $X$를 통해 표현될 수 있음을 보장해준다. (자세한 내용은 M. M. Rao의 저서 (1984), Proposition 3, p.7을 참고)

### Doob-Dynkin Lemma

> **Lemma 2.1.2**
> $X, Y : \Omega \to \mathbb{R}^n$가 두 함수라고 하자. 그러면 $Y$가 $\mathcal{H}_X$-측정 가능하다는 것은 다음과 동치이다:
> 
> 어떤 Borel 측정 가능 함수 $g : \mathbb{R}^n \to \mathbb{R}^n$가 존재하여 다음이 성립한다.
> 
> $$
> Y = g(X)
> $$
> 
> 이 정리는 직관적으로 "만약 $Y$가 $X$만을 통해 관찰될 수 있다면, $Y$는 사실상 $X$에 어떤 함수를 적용한 것"임을 말해준다. 즉, $Y$는 $X$에 종속된 구조를 가진다.
{: .definition-box }

이제부터는 확률 공간 $(\Omega, \mathcal{F}, P)$가 **완비된 확률 공간**이라고 가정한다. 확률 변수 $X : \Omega \to \mathbb{R}^n$는 $\mathcal{F}$-측정 가능 함수이며, 모든 확률 변수는 $\mathbb{R}^n$ 위의 확률 측도 $\mu_X$를 유도한다. 이 측도는 다음과 같이 정의된다:

$$
\mu_X(B) := P(X^{-1}(B))
$$

여기서 $B$는 $\mathbb{R}^n$의 Borel 집합이다. 이 측도 $\mu_X$는 **확률 변수 $X$의 분포(distribution)**라고 불린다.

확률 변수 $X$의 절댓값이 적분 가능할 때, 즉

$$
\int_\Omega |X(\omega)| \, dP(\omega) < \infty
$$

이면, 다음과 같이 정의된 수

$$
E[X] := \int_\Omega X(\omega) \, dP(\omega) = \int_{\mathbb{R}^n} x \, d\mu_X(x)
$$

는 **확률 변수 $X$의 기대값(expectation)**이라고 한다.

이는 두 방식으로 해석될 수 있다:

- **확률 공간 $\Omega$ 위에서 직접 적분**하거나,
- **확률 변수 $X$의 분포 $\mu_X$에 대해 적분**하는 방식이다.

이 두 방식은 동일한 값을 가지며, **확률 변수의 분포를 통해 기대값을 재구성할 수 있음을 보여준다.**

함수 $f : \mathbb{R}^n \to \mathbb{R}$가 Borel 측정 가능하고, $f(X(\omega))$이 적분 가능할 때,

$$
\int_\Omega |f(X(\omega))| \, dP(\omega) < \infty
$$

다음 식이 성립한다:

$$
E[f(X)] := \int_\Omega f(X(\omega)) \, dP(\omega) = \int_{\mathbb{R}^n} f(x) \, d\mu_X(x)
$$

이 식은 **변수 변환 공식 (change of variable formula)**의 확률론적 표현이라 할 수 있으며, 실제 계산에서 매우 유용하게 활용된다고 한다.

### $L^p$-spaces

확률 변수 $X : \Omega \to \mathbb{R}^n$가 주어졌다고 하자.  
그리고 $p \in [1, \infty)$인 어떤 고정된 상수가 있을 때, 우리는 **$L^p$-norm**을 다음과 같이 정의한다:

$$
\|X\|_p = \|X\|_{L^p(P)} := \left( \int_\Omega |X(\omega)|^p \, dP(\omega) \right)^{1/p}
$$

이 norm은 확률 변수의 "크기" 또는 "분산 정도"를 수치적으로 측정하는 도구로 볼 수 있다. $X(\omega)$의 절댓값의 $p$제곱을 평균 낸 다음, $p$제곱근을 취하는 방식이다. 그런데, $p = \infty$인 경우에는 위의 정의를 그대로 쓸 수 없기 때문에, 다음과 같이 정의한다:

$$
\|X\|_\infty = \|X\|_{L^\infty(P)} := \inf \lbrace N \in \mathbb{R} \mid |X(\omega)| \leq N \text{ almost surely} \rbrace
$$

즉, $X(\omega)$의 크기가 거의 모든 $\omega \in \Omega$에 대해 $N$ 이하가 되도록 하는 **최소한의 상한값**을 의미한다. 이 정의는 $X$가 거의 어디서나 유한한 범위 내에 머무는지를 측정한다.

이제 $L^p$ 공간 자체는 다음과 같이 정의된다:

$$
L^p(P) = L^p(\Omega) := t\lbrace X : \Omega \to \mathbb{R}^n \mid \|X\|_p < \infty \rbrace
$$

즉, $L^p$ 공간은 **$p$-norm이 유한한 모든 확률 변수들의 모임**이다.

$L^p$ norm은 선형 공간에서의 거리 개념을 일반화하는 역할을 한다.  
이 norm으로 인해 $L^p$ 공간은 **바나흐 공간(Banach space)**이 된다.  
즉, **norm 공간이며 완비성**을 가진다. 이는 "무한급수로 정의된 함수열도 극한이 존재하면 그 안에 머문다"는 성질이다.

특히 $p = 2$일 경우에는 $L^2(P)$ 공간이 더 특별한 성질을 가진다.  
이 경우에는 **힐베르트 공간(Hilbert space)**이 되며, 이는 **내적(inner product)**을 갖는 완비 공간이다.

이때 내적은 다음과 같이 정의된다:

$$
(X, Y)_{L^2(P)} := E[X \cdot Y] \quad \text{for } X, Y \in L^2(P)
$$

즉, 두 확률 변수 $X$, $Y$의 내적은 그 곱의 기대값이 된다. 이 내적 구조 덕분에 $L^2$ 공간에서는 직교성, 정사영, 최소 제곱 추정 등 다양한 기하적 기법들을 적용할 수 있다. 이것은 확률론뿐 아니라 신호 처리, 기계 학습, 통계학 등에서도 핵심적인 역할을 한다. (익숙하다..!)

### Independence (독립성)

> **Definition 2.1.3**
> 두 사건 $A, B \in \mathcal{F}$가 *독립(independent)*이라고 하려면 다음을 만족해야 한다:
>
> $$
> P(A \cap B) = P(A) \cdot P(B)
> $$
>
> 더 일반적으로, 가측 집합들의 족 $\mathcal{A} = \lbrace \mathcal{H}_i; i \in I \rbrace$가 *독립*이라고 하려면, 모든 서로 다른 인덱스 $i_1, \dots, i_k$에 대해 다음 조건이 성립해야 한다:
>
> $$
> P(H_{i_1} \cap \cdots \cap H_{i_k}) = P(H_{i_1}) \cdots P(H_{i_k})
> \quad \text{for all } H_{i_j} \in \mathcal{H}_{i_j}
> $$
>
> 확률 변수 집합 $\lbrace X_i \rbrace_{i \in I}$가 *독립*이라는 것은, 그에 의해 생성된 시그마 대수들의 족 $\lbrace \mathcal{H}_{X_i} \rbrace$가 독립이라는 것을 의미한다. 특히 두 확률 변수 $X, Y : \Omega \to \mathbb{R}$가 독립이라면 다음이 성립한다:
>
> $$
> E[XY] = E[X] \cdot E[Y]
> $$
>
> 단, $E[\|X\|] < \infty$이고 $E[\|Y\|] < \infty$일 때에만 위 식이 성립한다.
> 
{: .definition-box }

### Stochastic Processes (확률 과정)

> **Definition 2.1.4**  
>
> 확률 과정이란 확률 변수들의 모임 $\lbrace X_t \rbrace_{t \in T}$이며, 이는 확률 공간 $(\Omega, \mathcal{F}, P)$ 위에 정의되고, $\mathbb{R}^n$ 값을 갖는다. 매개변수 공간 $T$는 일반적으로 $[0, \infty)$와 같은 반직선이며, 경우에 따라 유한 구간 $[a, b]$, 음이 아닌 정수들의 집합 $\mathbb{N}$, 혹은 $\mathbb{R}^n$의 부분집합이 될 수도 있다.
>
> $t \in T$를 고정하면 다음과 같이 하나의 확률 변수 $X_t$가 정의된다:
>
> $$
> \omega \mapsto X_t(\omega), \quad \omega \in \Omega
> $$
>
> 반대로, $\omega \in \Omega$를 고정하면 다음과 같이 경로(path)라는 함수를 얻는다:
>
> $$
> t \mapsto X_t(\omega), \quad t \in T
> $$
>
> 이 경로는 실현된 실험 결과 $\omega$에 대한 시계열 함수라고 생각할 수 있다. 예를 들어, $\omega$는 어떤 입자(particle)의 식별자, $t$는 시간, $X_t(\omega)$는 그 시간 $t$에 해당 입자의 위치나 상태를 나타낸다고 볼 수 있다.
{: .definition-box }

#### 확률 과정을 함수 $X(t, \omega)$로 보는 관점

실제로는 $X_t(\omega)$ 대신 $X(t, \omega)$라고 쓰는 것이 편리한 경우가 많다. 즉, 확률 과정을 두 변수의 함수로 본다:

$$
(t, \omega) \mapsto X(t, \omega)
$$

이는 $T \times \Omega \to \mathbb{R}^n$의 함수이며, 확률 해석과 해석학적으로 매우 자연스러운 관점이다. 확률 해석에서는 $(t, \omega)$에 대해 **공동 측정 가능성 (joint measurability)**이 중요하게 다루어진다.

#### 경로를 함수로 해석하는 관점

각 $\omega$는 $t \mapsto X_t(\omega)$라는 함수로 생각될 수 있다. 이 함수는 $T$에서 $\mathbb{R}^n$으로 가는 함수이며, 따라서 전체 $\Omega$는 다음과 같은 함수 공간의 부분집합으로 볼 수 있다:

$$
\Omega \subseteq \widetilde{\Omega} := (\mathbb{R}^n)^T
$$

즉, $\Omega$는 $T$에서 $\mathbb{R}^n$으로 가는 모든 함수들의 집합의 부분집합이다. 이 관점에서는 시그마 대수 $\mathcal{F}$가 다음과 같은 형태의 집합들로 생성된 $\sigma$-대수를 포함한다:

$$
\left\lbrace \omega \in \Omega \mid \omega(t_1) \in F_1, \dots, \omega(t_k) \in F_k \right\rbrace, \quad F_i \subset \mathbb{R}^n \text{ Borel 집합}
$$

따라서 확률 과정을 다음과 같이 해석할 수도 있다:

> 확률 과정은 측도 공간 $((\mathbb{R}^n)^T, \mathcal{B})$ 위의 확률 측도 $P$로 본다.

#### 유한 차원 분포 (finite-dimensional distributions)

확률 과정 $X = \lbrace X_t \rbrace_{t \in T}$에 대해, 유한 개의 시점 $(t_1, \dots, t_k)$를 고르면 $X_{t_1}, \dots, X_{t_k}$의 **공동 분포**를 생각할 수 있다.

이를 다음과 같은 측도로 정의한다:

$$
\mu_{t_1, \dots, t_k}(F_1 \times \cdots \times F_k) := P\left[ X_{t_1} \in F_1, \dots, X_{t_k} \in F_k \right]
$$

여기서 $F_1, \dots, F_k$는 $\mathbb{R}^n$ 위의 Borel 집합들이다.

이러한 **모든 유한 차원 분포들의 집합**은 확률 과정 $X$의 많은 (그러나 전부는 아님) 성질을 결정한다.

#### Kolmogorov 확장 정리 (Kolmogorov's Extension Theorem)

앞서 살펴본 것처럼, 확률 과정 $ X = \lbrace X_t\rbrace_{t \in T} $는 유한한 시점들에서의 확률 변수 집합 $\lbrace X_{t_1}, \dots, X_{t_k}\rbrace$의 **공동 분포**를 통해 많은 정보를 담고 있다. 이러한 유한 차원 분포들이 잘 정의되어 있고, 특정한 일관성 조건을 만족한다면, **실제로 전체 확률 과정을 구성할 수 있다**는 것이 Kolmogorov의 확장 정리이다.

> **정리 2.1.5 (Kolmogorov's Extension Theorem)**  
>  
> 집합 $T$ 위의 모든 유한 시점 집합 $\lbrace t_1, \dots, t_k\rbrace \subset T$에 대해, $\mathbb{R}^{nk}$ 위의 확률 측도 $\nu_{t_1, \dots, t_k}$가 주어졌다고 하자. 이때 이들 분포가 다음의 두 가지 일관성 조건을 만족한다고 가정한다:
>
> 1. 치환 불변성 (Permutation Invariance)
>    모든 순열 $\sigma$에 대해 다음이 성립한다:
>
>    $$
>    \nu_{t_{\sigma(1)}, \dots, t_{\sigma(k)}}(F_1 \times \cdots \times F_k)  = \nu_{t_1, \dots, t_k}(F_{\sigma^{-1}(1)} \times \cdots \times F_{\sigma^{-1}(k)}) \tag{K1}
>    $$
> 2. 마진 일관성 (Marginal Consistency)  
>   모든 $m \in \mathbb{N}$에 대해 다음이 성립한다:
>
>    $$
>    \nu_{t_1, \dots, t_k}(F_1 \times \cdots \times F_k) = \nu_{t_1, \dots, t_{k+m}}(F_1 \times \cdots \times F_k \times \mathbb{R}^n \times \cdots \times \mathbb{R}^n) \tag{K2}
>    $$
>
>    여기서 오른쪽의 곱집합은 총 $k + m$개의 성분을 가진다.
{: .definition-box }

이러한 조건이 모두 만족되면, 확률 공간 $(\Omega, \mathcal{F}, P)$와 확률 과정 $ \lbrace X_t \rbrace _{t \in T}$가 존재하여 다음을 만족한다:

$$
\nu_{t_1, \dots, t_k}(F_1 \times \cdots \times F_k)
= P[X_{t_1} \in F_1, \dots, X_{t_k} \in F_k]
$$

이는 곧, 주어진 유한 차원 분포들을 가진 확률 과정을 실제로 **구성할 수 있음**을 보장한다.

## Conclusion
이번 쳅터에서는 확률론의 기초적인 개념들을 살펴보았다. 수학적 개념이 생소하고 힘든 것도 있었고, 그럭저럭 이해할만 했던 것도 있었던 것 같다. 2.2장도 이 포스트에 같이 쓰려고 했는데, 생각보다 길어져서 다음 포스트로 쓰려고 한다.

---
## Reference

[^1]: Bernt Øksendal, *Stochastic Differential Equations*, Springer, 2003. DOI: [10.1007/978-3-642-14394-6](https://doi.org/10.1007/978-3-642-14394-6).
[^2]: 공간이 '빈 틈 없이 채워져 있음'을 의미한다.
